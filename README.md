# ğŸ“š RAG Course Assistant

This project is a **Retrieval-Augmented Generation (RAG)** system designed as a **course assistant**.  
It helps students quickly find where topics are explained in long video lectures.

## ğŸš€ Features
- ğŸ¥ Extracts audio from course videos using `ffmpeg`
- ğŸ“ Transcribes + translates audio into English with **Whisper**
- ğŸ” Splits into chunks and generates embeddings with **bge-m3 (Ollama)**
- ğŸ“‚ Stores embeddings with `joblib`
- â“ Retrieves top chunks for a userâ€™s query
- ğŸ¤– Generates natural answers using **Llama3.2**

## ğŸ› ï¸ Tech Stack
- Python
- Whisper
- Ollama (`bge-m3`, `llama3.2`)
- scikit-learn (cosine similarity)
- Pandas / NumPy
- ffmpeg

## ğŸ“– How it Works
1. Convert course videos â†’ audio (`ffmpeg`)
2. Transcribe + translate audio (`Whisper`)
3. Break into chunks + embed (`bge-m3`)
4. Store embeddings in dataframe (`joblib`)
5. On query â†’ retrieve top-k similar chunks (`cosine similarity`)
6. Generate human-like answer (`Llama3.2`)


# Install dependencies
pip install -r requirements.txt


## ğŸ“¸ Screenshots

### ğŸ”¹ JSON Output
Transcribed chunks stored as JSON:  
![JSON Sample](images/sample%20json%20file.png)

### ğŸ”¹ Sample Prompt
Prompt:  "where is html concluded"
![Embeddings](images/prompt.png)

### ğŸ”¹ Response
Example of how a user query gets answered:  
![Prompt and Response](images/response.png)



## ğŸ“‚ Project Structure

```text
RAG-Project/
â”œâ”€â”€ audios/              # extracted audio files (ignored in git)
â”œâ”€â”€ videos/              # original course videos (ignored in git)
â”œâ”€â”€ jsons/               # Whisper transcripts (ignored in git)
â”œâ”€â”€ process_incoming.py  # main RAG pipeline
â”œâ”€â”€ video_to_mp3.py      # video â†’ audio
â”œâ”€â”€ mp3_to_json.py       # audio â†’ transcript
â”œâ”€â”€ read_chunks.py       # build embeddings
â”œâ”€â”€ embeddings.joblib    # stored embeddings (ignored in git)
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore




